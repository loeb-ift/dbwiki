# DB-GPT-WEBUI

這是一個基於 Vanna.ai 和 Flask 的網頁應用程式，旨在提供一個圖形化介面，讓使用者可以透過自然語言與資料庫進行互動。使用者可以上傳自己的資料集、訓練 AI 模型，並透過提問來查詢資料。

## 功能特色

- **多使用者支援**：每個使用者擁有獨立的訓練資料和資料集。
- **圖形化訓練介面**：透過網頁介面輕鬆管理 DDL、業務文件和 SQL 問答配對。
- **動態日誌分析**：在每次提問後，系統會自動收集所有檢索過程的日誌，並發送給大型語言模型 (LLM) 進行分析，以提供更深入的洞察。
- **提示詞歷史紀錄**：自動保存每一次發送給 LLM 的完整提示詞，方便使用者進行分析和優化。
- **分塊處理**：自動將過長的提示詞分塊，以避免超出 LLM 的處理上限。

## 環境設定

### 1. 安裝必要的 Python 套件

在開始之前，請確保您已經安裝了 Python 3.8 或更高版本。然後，透過 pip 安裝所有必要的套件：

```bash
pip install -r requirements.txt
```

### 2. 設定 LLM 連線

本專案支援多種大型語言模型 (LLM)，包括本地端的 Ollama，以及雲端的 OpenAI、Anthropic (Claude) 和 Google (Gemini)。

首先，複製 `.env.example` 檔案，並將其重新命名為 `.env`：

```bash
cp .env.example .env
```

接著，編輯 `.env` 檔案，**選擇其中一種** LLM 供應商，並填入對應的設定。程式會自動偵測您填寫的是哪一種。

**範例 1：使用本地端的 Ollama**
```
# --- LLM Configuration ---
# 1. Ollama (Local LLM)
OLLAMA_HOST=http://your-ollama-server-ip:11434
OLLAMA_MODEL=your-model-name:latest
```

**範例 2：使用 OpenAI**
```
# --- LLM Configuration ---
# 2. OpenAI
OPENAI_API_KEY="sk-..."
OPENAI_MODEL="gpt-4-turbo"
```

**範例 3：使用 Anthropic (Claude)**
```
# --- LLM Configuration ---
# 3. Anthropic (Claude)
ANTHROPIC_API_KEY="sk-ant-..."
ANTHROPIC_MODEL="claude-3-opus-20240229"
```

**範例 4：使用 Google (Gemini)**
```
# --- LLM Configuration ---
# 4. Google (Gemini)
GOOGLE_API_KEY="..."
GOOGLE_MODEL="gemini-1.5-pro-latest"
```

**重要**：請確保一次只啟用一種 LLM 的設定，將其他供應商的設定保持註解狀態。

## 啟動應用程式

完成環境設定後，您可以透過以下指令來啟動 Flask 網頁應用程式：

```bash
python app.py
```

應用程式預設會在 `0.0.0.0:5001` 上執行。您可以在瀏覽器中開啟 `http://localhost:5001` 來存取網頁介面。

## 網頁介面使用方法

### 1. 登入

請使用您在 `.env` 檔案中透過 `APP_USERS` 變數設定的帳號和密碼進行登入。

### 2. 新增與選擇資料集

- **新增資料集**：點擊右上角的「+ 新增」按鈕。在彈出的視窗中，為您的資料集命名，並選擇一個或多個要上傳的 CSV 檔案。系統會為每個 CSV 檔案在資料庫中建立一個對應的資料表。
- **選擇資料集**：從下拉式選單中選擇您想要操作的資料集。選擇後，下方的訓練介面將會被啟用。

### 3. 管理訓練資料

選擇資料集後，您可以開始管理該資料集的訓練資料。

- **選擇資料表**：您可以選擇針對「全局/跨資料表」或某個特定的資料表 (CSV) 來進行訓練。
- **Schema (DDL)**：當您選擇一個資料表時，其 DDL (資料表定義語言) 會自動顯示在此處。選擇「全局」則會顯示所有資料表的 DDL。
- **知識背景文件**：在此處輸入與所選資料表或整個資料集相關的業務知識、欄位定義、常用縮寫等。您也可以透過檔案上傳的方式來新增。完成後，請點擊「儲存文件」。
- **SQL 問答配對**：在此處新增「問題」（自然語言）與其對應「SQL 語法」的配對。這是訓練模型理解如何將問題轉換為 SQL 的關鍵。您可以手動新增，也可以透過上傳 `.sql` 檔案來批次生成。

### 4. 訓練模型

當您準備好 DDL、文件和問答配對後，點擊「重新訓練整個模型」按鈕。系統會將這些資料向量化並儲存起來，用於後續的提問。

### 5. 提出問題

模型訓練完成後，「提出問題」區塊將會啟用。

1.  在輸入框中用自然語言輸入您的問題（例如：「找出利潤潛力高但銷售不足的產品線」）。
2.  點擊「提出問題」按鈕。
3.  系統會開始執行以下流程：
    - **思考過程**：顯示 Vanna.ai 檢索 DDL、文件和相似問答的過程。
    - **SQL 查詢思考過程分析表**：顯示由 LLM 根據所有日誌分析後產生的思考過程摘要。
    - **生成的 SQL**：顯示最終由 AI 生成的 SQL 語法。
    - **查詢結果**：顯示執行 SQL 後的資料表結果。

### 6. 查看提示詞歷史紀錄

每一次您提出問題時，系統發送給 LLM 進行分析的完整提示詞，都會被自動保存到專案根目錄下的 `prompt_history` 資料夾中。您可以隨時查看這些 `.txt` 檔案，以了解 AI 的「思考過程」，並根據這些資訊來優化您的訓練資料或提示詞範本 (`prompts/ask_analysis_prompt.txt`)。
# Vanna.AI Web 介面

這是一個基於 Vanna.AI 和 Flask 的互動式 Web 應用程式，旨在簡化資料庫的自然語言查詢。它允許使用者輕鬆連接到各種資料庫，透過自然語言訓練文本到 SQL 的模型，並自動生成和執行 SQL 查詢，從而實現資料的快速洞察和分析。

## 特性

- **多種資料庫支援**: 透過 SQLAlchemy 輕鬆連接到 PostgreSQL、MySQL、MS SQL Server、SQLite 等多種資料庫。
- **智慧型訓練資料管理**: 支援使用 DDL (資料定義語言)、資料庫文件和 SQL 問答對進行模型訓練，並自動管理訓練資料，避免重複。
- **自動問題生成**: 利用 Vanna 的強大功能自動生成訓練用的問答對，加速模型訓練過程。
- **知識圖譜視覺化**: 將資料庫 Schema 以直觀的知識圖譜形式展示，幫助使用者理解資料庫結構。
- **自然語言查詢**: 允許使用者以自然語言提出業務問題，應用程式將自動生成並執行相應的 SQL 查詢，並顯示結果。
- **Ollama 整合**: 支援使用 Ollama 進行本地大型語言模型 (LLM) 的整合，提供更靈活的部署選項。
- **可擴展性**: 模組化設計，易於擴展和整合其他 Vanna 向量儲存和 LLM 服務。

## 安裝

1.  **克隆倉庫**:
    ```bash
    git clone https://github.com/YOUR_USERNAME/YOUR_REPOSITORY.git
    cd YOUR_REPOSITORY
    ```
    請將 `YOUR_USERNAME` 和 `YOUR_REPOSITORY` 替換為您的實際 GitHub 用戶名和倉庫名稱。

2.  **創建並激活虛擬環境**:
    ```bash
    python -m venv .venv
    source .venv/bin/activate
    ```

3.  **安裝依賴**:
    ```bash
    pip install -r requirements.txt
    ```
    此命令將安裝所有必要的 Python 依賴項。

## 配置

1.  **複製 `.env.example` 文件並重命名為 `.env`**:
    ```bash
    cp .env.example .env
    ```
    然後編輯 `.env` 文件並填寫以下變量：

    ```
    # Ollama LLM 配置 (可選，如果使用本地 LLM)
    OLLAMA_HOST=http://localhost:11434
    OLLAMA_MODEL=llama3

    # ChromaDB 集合名稱 (Vanna 預設向量儲存)
    CHROMA_COLLECTION_NAME=my_vanna_collection

    # 訓練資料 SQLite 資料庫路徑
    TRAINING_DATA_DB_PATH=./training_data_qa.db
    ```
    請根據您的實際環境修改這些配置。如果您不使用 Ollama，可以將相關行註釋掉或留空。

2.  **確保 Ollama 正在運行** (如果使用)。

## 運行應用程式

```bash
python app.py
```

然後在您的瀏覽器中打開 `http://127.0.0.1:5001`。

## 使用指南

這個 Web 介面提供了一個直觀的方式來與 Vanna.AI 互動。以下是主要的操作流程：

1.  **連接資料庫**:
    *   在網頁介面的「1. 連接到資料庫」部分，您需要輸入您的資料庫連接資訊。這通常是一個連接字串，例如：
        *   SQLite: `sqlite:///./my_database.db`
        *   PostgreSQL: `postgresql://user:password@host:port/database`
        *   MySQL: `mysql+mysqlconnector://user:password@host:port/database`
        *   MS SQL Server: `mssql+pyodbc://user:password@host:port/database?driver=ODBC+Driver+17+for+SQL+Server`
    *   填寫完畢後，點擊「連接」按鈕。
    *   成功連接後，應用程式將會自動提取資料庫的 DDL (資料定義語言)，並顯示在「DDL 陳述式」文本框中。這些 DDL 將用於訓練 Vanna 模型，幫助它理解資料庫結構。

2.  **訓練模型**:
    Vanna 模型需要訓練資料來學習如何將自然語言問題轉換為 SQL 查詢。您可以透過以下幾種方式提供訓練資料：
    *   **手動添加 DDL**: 在「DDL 陳述式」文本框中輸入或修改 DDL 語句。
    *   **手動添加文件**: 在「文件」文本框中輸入與資料庫相關的說明或業務邏輯。
    *   **手動添加問答對 (QA)**: 在「問答對」部分，您可以輸入一個自然語言問題和對應的 SQL 查詢。
    *   **自動生成問題**: 點擊「自動生成問題」按鈕，Vanna 將利用其智慧功能，根據您的資料庫 Schema 自動創建新的問答對。這些問答對將自動提交給模型進行訓練，以豐富模型的知識庫。
    *   **提交訓練數據**: 在輸入或生成任何訓練數據後，點擊「訓練模型」按鈕。所有提供的訓練數據將被提交給 Vanna 模型進行學習。
    *   **避免重複訓練**: 應用程式會自動檢查並跳過已存在的 DDL 和文件訓練，確保訓練效率。

3.  **查看訓練資料**:
    *   您可以點擊「獲取訓練資料」按鈕來查看當前 Vanna 模型中已有的訓練數據。這將顯示所有已訓練的 DDL、文件和問答對。

4.  **提出問題**:
    *   在「提出問題」部分的文本框中，輸入您的自然語言業務問題。例如：「顯示每個城市的總銷售額」。
    *   點擊「提問」按鈕。
    *   應用程式將利用訓練好的 Vanna 模型生成相應的 SQL 查詢，並在下方顯示查詢結果。

5.  **管理問答對**:
    *   **更新問答對**: 如果您想修改已有的問答對，可以在「問答對」部分進行編輯，然後點擊「更新問答對」。
    *   **添加問答對**: 您也可以直接在「問答對」部分添加新的問題和 SQL 查詢，然後點擊「添加問答對」。
    *   **重新生成問題**: 如果您對自動生成的問題不滿意，可以點擊「重新生成問題」來獲取新的建議。

## 故障排除

- **Ollama 連接問題**: 確保 Ollama 服務正在運行，並且 `.env` 文件中的 `OLLAMA_HOST` 和 `OLLAMA_MODEL` 配置正確。
- **資料庫連接錯誤**: 檢查您在應用程式中輸入的資料庫連接字串是否正確，以及資料庫服務是否可訪問。
- **重複訓練訊息**: 應用程式已實作機制避免重複訓練 DDL 和文件。如果仍然看到重複訊息，請檢查 `training_data_qa.db` 檔案的完整性。
- **SQL 語法錯誤**: 如果生成的 SQL 查詢出現語法錯誤，請嘗試提供更清晰的自然語言問題，或手動修正 DDL 和文件中的錯誤。

## 貢獻

歡迎對此專案做出貢獻！請隨時提交問題或拉取請求。

## 許可證

此專案根據 MIT 許可證發布。詳情請參閱 `LICENSE` 文件。
