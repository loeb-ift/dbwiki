# DBWiki 多用户应用测试计划

## 一、测试目标

通过系统化测试，确保DBWiki多用户应用的以下方面符合要求：
1. 用户认证与会话管理功能正常
2. 数据集管理功能完整可用
3. 训练数据管理功能健壮
4. AI模型训练和问答功能准确
5. 系统整体性能和稳定性达标

## 二、测试环境

- 操作系统：macOS
- Python版本：根据项目要求
- Flask版本：根据项目要求
- 数据库：SQLite
- AI模型：Ollama（需要配置OLLAMA_MODEL和OLLAMA_HOST环境变量）
- 测试工具：pytest, requests

## 三、测试内容与测试用例

### 1. 用户认证与会话管理

| 测试用例ID | 测试功能 | 测试步骤 | 预期结果 | 优先级 |
|------------|----------|----------|----------|--------|
| TC-001     | 成功登录 | 1. 发送POST请求到/login，提供正确的用户名和密码 | 返回302重定向到/index，会话中包含用户名 | 高 |
| TC-002     | 失败登录 | 1. 发送POST请求到/login，提供错误的用户名和密码 | 页面显示错误信息"Invalid credentials" | 高 |
| TC-003     | 未登录访问首页 | 1. 在未登录状态下访问/ | 自动重定向到/login页面 | 高 |
| TC-004     | 登出功能 | 1. 登录后发送GET请求到/logout | 重定向到/login页面，会话被清除 | 高 |
| TC-005     | 未授权访问API | 1. 在未登录状态下访问/api/datasets | 返回401状态码和认证错误信息 | 高 |

### 2. 数据集管理

| 测试用例ID | 测试功能 | 测试步骤 | 预期结果 | 优先级 |
|------------|----------|----------|----------|--------|
| TC-101     | 获取数据集列表 | 1. 登录后发送GET请求到/api/datasets | 返回状态码200和数据集列表 | 高 |
| TC-102     | 创建数据集 | 1. 登录后发送POST请求到/api/datasets，包含数据集名称和CSV文件 | 返回状态码201和新创建的数据集信息 | 高 |
| TC-103     | 创建数据集缺少必填项 | 1. 发送POST请求到/api/datasets，不提供数据集名称或文件 | 返回状态码400和错误信息 | 高 |
| TC-104     | 激活数据集 | 1. 登录后发送POST请求到/api/datasets/activate，提供有效的dataset_id | 返回状态码200，包含表格名称和DDL语句 | 高 |
| TC-105     | 激活不存在的数据集 | 1. 发送POST请求到/api/datasets/activate，提供不存在的dataset_id | 返回状态码400或500和错误信息 | 中 |

### 3. 训练数据管理

| 测试用例ID | 测试功能 | 测试步骤 | 预期结果 | 优先级 |
|------------|----------|----------|----------|--------|
| TC-201     | 获取训练数据 | 1. 登录并激活数据集后，发送GET请求到/api/training_data | 返回文档、问答对和分页信息 | 高 |
| TC-202     | 保存文档 | 1. 登录并激活数据集后，发送POST请求到/api/save_documentation，包含文档内容 | 返回状态码200和成功消息 | 高 |
| TC-203     | 清空文档 | 1. 发送POST请求到/api/save_documentation，提供空文档内容 | 成功删除文档并返回相应消息 | 中 |
| TC-204     | 添加问答对 | 1. 登录并激活数据集后，发送POST请求到/api/add_qa_question，包含问题和SQL | 返回状态码200和成功消息 | 高 |
| TC-205     | 添加问答对缺少必填项 | 1. 发送POST请求到/api/add_qa_question，不提供问题或SQL | 返回状态码400和错误信息 | 高 |

### 4. AI模型训练与问答功能

| 测试用例ID | 测试功能 | 测试步骤 | 预期结果 | 优先级 |
|------------|----------|----------|----------|--------|
| TC-301     | 模型训练 | 1. 登录并激活数据集后，发送POST请求到/api/train，包含DDL、文档或问答对 | 成功接收流式响应，显示训练进度 | 高 |
| TC-302     | 提问生成SQL | 1. 登录并激活数据集后，发送POST请求到/api/ask，提供自然语言问题 | 成功接收流式响应，包含生成的SQL和执行结果 | 高 |
| TC-303     | 从SQL文件生成问答对 | 1. 登录并激活数据集后，发送POST请求到/api/generate_qa_from_sql，上传SQL文件 | 成功接收流式响应，显示生成进度和问答对 | 高 |
| TC-304     | 生成文档 | 1. 登录并激活数据集后，发送POST请求到/api/generate_documentation，提供DDL | 返回生成的文档内容 | 高 |
| TC-305     | 分析模式 | 1. 登录并激活数据集后，发送POST请求到/api/analyze_schema | 返回模式分析结果 | 高 |

### 5. 错误处理与边界情况

| 测试用例ID | 测试功能 | 测试步骤 | 预期结果 | 优先级 |
|------------|----------|----------|----------|--------|
| TC-401     | 处理无效的SQL文件 | 1. 上传非.sql文件到/api/generate_qa_from_sql | 返回状态码400和错误信息 | 中 |
| TC-402     | 处理执行失败的SQL | 1. 在ask功能中使用会导致SQL错误的问题 | 流式响应中包含错误信息 | 中 |
| TC-403     | 处理大数据集分页 | 1. 创建包含超过10条问答对的数据集，测试分页功能 | 正确返回分页数据和总页数 | 中 |
| TC-404     | 测试Ollama连接失败 | 1. 故意配置错误的OLLAMA_HOST | 相关功能返回适当的错误信息 | 中 |

## 四、测试方法

1. **单元测试**：使用pytest框架测试各个函数的独立功能
2. **集成测试**：测试不同组件之间的交互
3. **API测试**：使用requests库测试所有RESTful API接口
4. **端到端测试**：模拟用户操作流程，从登录到完成任务的完整测试
5. **性能测试**：测试在较大数据集和并发请求下的系统性能
6. **安全测试**：测试未授权访问、输入验证等安全相关功能

## 五、测试数据准备

1. 测试用户凭据：使用代码中预定义的用户名和密码
2. 测试CSV文件：准备多个不同大小和结构的CSV文件
3. 测试SQL文件：准备包含多个SQL查询的文件
4. 测试问题集：准备各种类型的自然语言问题

## 六、测试环境搭建

1. 克隆代码库：`git clone <repository_url>`
2. 安装依赖：`pip install -r requirements.txt`
3. 设置环境变量：创建`.env`文件，配置OLLAMA_MODEL和OLLAMA_HOST
4. 启动Ollama服务
5. 运行测试：`pytest`

## 七、测试执行计划

1. 首先执行单元测试，确保各个函数独立工作正常
2. 然后执行API测试，验证所有接口功能
3. 接着进行集成测试，确保组件间交互正常
4. 执行端到端测试，模拟真实用户场景
5. 最后进行性能测试和安全测试

## 八、预期输出与评估标准

1. 所有测试用例通过率达到100%
2. 每个API接口响应时间不超过2秒（大数据集和复杂操作除外）
3. 系统能够处理至少5个并发用户请求
4. 错误处理机制完善，提供清晰的错误信息

## 九、风险与应对措施

1. **Ollama服务依赖**：确保测试环境中Ollama服务稳定运行，准备备用测试方案
2. **测试数据大小**：使用合适大小的测试数据，避免测试时间过长
3. **环境配置问题**：详细记录环境配置过程，便于重现和排查问题
4. **并发测试复杂性**：使用专业的性能测试工具或框架进行并发测试

## 十、测试报告

测试完成后，生成详细的测试报告，包含：
1. 测试执行摘要
2. 测试通过率统计
3. 失败测试用例详情及分析
4. 性能测试结果
5. 改进建议